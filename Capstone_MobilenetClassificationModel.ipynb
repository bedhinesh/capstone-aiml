{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Capstone_MobilenetClassificationModel",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NcLhOvl5YILlnyy3UCAXM9u0skp7EBPX",
      "authorship_tag": "ABX9TyO9ssSUl51QPkDDFdvwY1Pb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bedhinesh/capstone-aiml/blob/rohan/Capstone_MobilenetClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYv1mDAtOCtO",
        "outputId": "42bf8ddd-84a9-4d73-9bc4-3665d566b451"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlDdkWCLO9BF"
      },
      "source": [
        "project_path = r'/content/drive/MyDrive/CapstoneProject/Data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBbYew4hPpXK"
      },
      "source": [
        "TRAIN_CSV = project_path + \"df_train.csv\"\n",
        "TEST_CSV = project_path + \"df_test.csv\"\n",
        "DATASET_FOLDER_TRAIN = project_path +\"car_data/car_data/train/\"\n",
        "DATASET_FOLDER_TEST = \"car_data/car_data/test/\"\n",
        "IMAGE_SIZE = 128 "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52svf8gfQzeJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/CapstoneProject/Data/df_train.csv',usecols=[\"Car_name\"]) \n",
        "y_test = pd.read_csv('/content/drive/MyDrive/CapstoneProject/Data/df_test.csv',usecols=[\"Car_name\"]) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZVmZ5-L_ms2",
        "outputId": "418c67f0-346a-4ad7-b9c1-8f9b273d669e"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8144, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy_rJQFiCsJx"
      },
      "source": [
        "\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-LUus56PHNE"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "# transform data\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmIYYFSy_l5C",
        "outputId": "d0058a59-b302-4196-bb3a-6fe3655510fe"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8144, 196)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxFnd4wQ5geQ",
        "outputId": "532ba8b6-4470-4a3f-d32d-7545765f8538"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8041, 196)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akoip-sAeyG0"
      },
      "source": [
        "from pickle import dump\n",
        "from pickle import load   ##load from existing\n",
        "# save the model\n",
        "X_train=load(open('/content/drive/MyDrive/CapstoneProject/Pickles/X_train.pkl', 'rb'))\n",
        "X_test=load(open('/content/drive/MyDrive/CapstoneProject/Pickles/X_test.pkl', 'rb'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffoOm9bOjykG",
        "outputId": "4c20ada7-e934-4843-e3e9-d89e0c5407dd"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8144, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtJ_tfDSjyrX",
        "outputId": "061960e5-32fc-4b3d-f749-62c3c1b5ffc8"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8041, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujeEzaiNnVuz",
        "outputId": "2056366b-addc-4dfa-a29c-7fadf12566ee"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "model = MobileNet(input_shape = X_train.shape[1:], dropout = 0.25, weights = None, \n",
        "                  classes = 196)\n",
        "model.compile(loss = 'categorical_crossentropy', \n",
        "               optimizer = Adam(lr = 1e-4, decay = 1e-6),\n",
        "               metrics = ['acc'])\n",
        "loss_history = []\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenet_1.00_128\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_preds (Conv2D)          (None, 1, 1, 196)         200900    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "predictions (Activation)     (None, 196)               0         \n",
            "=================================================================\n",
            "Total params: 3,429,764\n",
            "Trainable params: 3,407,876\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itx0aAHzE6B-"
      },
      "source": [
        "\"\"\"## CNN model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#### Input Layer ####\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
        "                 activation='relu', input_shape=(128, 128, 3)))\n",
        "\n",
        "#### Convolutional Layers ####\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))  # Pooling\n",
        "model.add(Dropout(0.2)) # Dropout\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#### Fully-Connected Layer ####\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(196, activation='softmax'))\n",
        "\n",
        "model.summary() # a handy way to inspect the architecture\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXi1ODGXkV9u"
      },
      "source": [
        "#model.compile(optimizer=\"adam\", loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpFlTplHkfKo",
        "outputId": "23e03418-d5cb-4354-e538-d95efb272b30"
      },
      "source": [
        "import tensorflow\n",
        "# Use earlystopping\n",
        "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='accuracy', patience=2, min_delta=0.1)\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_split=.2, epochs=100, batch_size=32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "204/204 [==============================] - 44s 59ms/step - loss: 5.4238 - acc: 0.0057 - val_loss: 5.3206 - val_acc: 0.0055\n",
            "Epoch 2/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.2898 - acc: 0.0067 - val_loss: 5.4033 - val_acc: 0.0031\n",
            "Epoch 3/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.2529 - acc: 0.0130 - val_loss: 5.5051 - val_acc: 0.0031\n",
            "Epoch 4/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.2394 - acc: 0.0085 - val_loss: 5.4156 - val_acc: 0.0037\n",
            "Epoch 5/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.2251 - acc: 0.0098 - val_loss: 5.2866 - val_acc: 0.0055\n",
            "Epoch 6/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.2012 - acc: 0.0122 - val_loss: 5.2832 - val_acc: 0.0104\n",
            "Epoch 7/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.1399 - acc: 0.0205 - val_loss: 5.2809 - val_acc: 0.0080\n",
            "Epoch 8/100\n",
            "204/204 [==============================] - 11s 52ms/step - loss: 5.1177 - acc: 0.0207 - val_loss: 5.2754 - val_acc: 0.0086\n",
            "Epoch 9/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 5.0646 - acc: 0.0220 - val_loss: 5.3051 - val_acc: 0.0110\n",
            "Epoch 10/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 5.0160 - acc: 0.0260 - val_loss: 5.2295 - val_acc: 0.0147\n",
            "Epoch 11/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 4.9396 - acc: 0.0333 - val_loss: 5.2421 - val_acc: 0.0110\n",
            "Epoch 12/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 4.8507 - acc: 0.0453 - val_loss: 5.4296 - val_acc: 0.0153\n",
            "Epoch 13/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 4.7729 - acc: 0.0549 - val_loss: 5.2537 - val_acc: 0.0184\n",
            "Epoch 14/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 4.6709 - acc: 0.0664 - val_loss: 5.2921 - val_acc: 0.0252\n",
            "Epoch 15/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 4.5320 - acc: 0.0933 - val_loss: 5.3266 - val_acc: 0.0190\n",
            "Epoch 16/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 4.4236 - acc: 0.0974 - val_loss: 5.3319 - val_acc: 0.0153\n",
            "Epoch 17/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 4.2099 - acc: 0.1489 - val_loss: 5.4267 - val_acc: 0.0190\n",
            "Epoch 18/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 4.0643 - acc: 0.1660 - val_loss: 5.6569 - val_acc: 0.0166\n",
            "Epoch 19/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 3.8764 - acc: 0.2025 - val_loss: 5.5361 - val_acc: 0.0221\n",
            "Epoch 20/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 3.6378 - acc: 0.2512 - val_loss: 5.6229 - val_acc: 0.0190\n",
            "Epoch 21/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 3.4205 - acc: 0.2945 - val_loss: 5.6745 - val_acc: 0.0196\n",
            "Epoch 22/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 3.2224 - acc: 0.3387 - val_loss: 5.8906 - val_acc: 0.0209\n",
            "Epoch 23/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 2.9428 - acc: 0.3978 - val_loss: 6.0480 - val_acc: 0.0178\n",
            "Epoch 24/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 2.7141 - acc: 0.4440 - val_loss: 5.8186 - val_acc: 0.0215\n",
            "Epoch 25/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 2.4157 - acc: 0.5234 - val_loss: 6.0027 - val_acc: 0.0172\n",
            "Epoch 26/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 2.1442 - acc: 0.5814 - val_loss: 6.1680 - val_acc: 0.0178\n",
            "Epoch 27/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 1.9732 - acc: 0.6105 - val_loss: 6.0493 - val_acc: 0.0203\n",
            "Epoch 28/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 1.7073 - acc: 0.6886 - val_loss: 6.2445 - val_acc: 0.0233\n",
            "Epoch 29/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 1.5286 - acc: 0.7172 - val_loss: 6.4207 - val_acc: 0.0166\n",
            "Epoch 30/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 1.3021 - acc: 0.7642 - val_loss: 6.3531 - val_acc: 0.0203\n",
            "Epoch 31/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 1.0759 - acc: 0.8141 - val_loss: 6.4817 - val_acc: 0.0184\n",
            "Epoch 32/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 1.0389 - acc: 0.8114 - val_loss: 6.4993 - val_acc: 0.0233\n",
            "Epoch 33/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.7795 - acc: 0.8770 - val_loss: 6.4459 - val_acc: 0.0233\n",
            "Epoch 34/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.6001 - acc: 0.9111 - val_loss: 6.6404 - val_acc: 0.0160\n",
            "Epoch 35/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.5656 - acc: 0.9150 - val_loss: 6.5796 - val_acc: 0.0221\n",
            "Epoch 36/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.5455 - acc: 0.9106 - val_loss: 6.7780 - val_acc: 0.0221\n",
            "Epoch 37/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.4811 - acc: 0.9265 - val_loss: 6.8201 - val_acc: 0.0246\n",
            "Epoch 38/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.3948 - acc: 0.9478 - val_loss: 6.8659 - val_acc: 0.0203\n",
            "Epoch 39/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.4067 - acc: 0.9300 - val_loss: 6.9549 - val_acc: 0.0147\n",
            "Epoch 40/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.3493 - acc: 0.9409 - val_loss: 7.0206 - val_acc: 0.0196\n",
            "Epoch 41/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2735 - acc: 0.9583 - val_loss: 6.9748 - val_acc: 0.0190\n",
            "Epoch 42/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2685 - acc: 0.9585 - val_loss: 7.2253 - val_acc: 0.0178\n",
            "Epoch 43/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2565 - acc: 0.9606 - val_loss: 7.1209 - val_acc: 0.0215\n",
            "Epoch 44/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2217 - acc: 0.9679 - val_loss: 7.2963 - val_acc: 0.0209\n",
            "Epoch 45/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2279 - acc: 0.9629 - val_loss: 7.2007 - val_acc: 0.0196\n",
            "Epoch 46/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1924 - acc: 0.9696 - val_loss: 7.5046 - val_acc: 0.0184\n",
            "Epoch 47/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.2166 - acc: 0.9650 - val_loss: 7.4172 - val_acc: 0.0196\n",
            "Epoch 48/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1833 - acc: 0.9743 - val_loss: 7.6125 - val_acc: 0.0203\n",
            "Epoch 49/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.2209 - acc: 0.9543 - val_loss: 7.5983 - val_acc: 0.0190\n",
            "Epoch 50/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.2008 - acc: 0.9639 - val_loss: 7.6211 - val_acc: 0.0184\n",
            "Epoch 51/100\n",
            "204/204 [==============================] - 11s 55ms/step - loss: 0.1820 - acc: 0.9704 - val_loss: 7.6269 - val_acc: 0.0190\n",
            "Epoch 52/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1514 - acc: 0.9737 - val_loss: 7.8545 - val_acc: 0.0184\n",
            "Epoch 53/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1679 - acc: 0.9723 - val_loss: 7.8278 - val_acc: 0.0123\n",
            "Epoch 54/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1725 - acc: 0.9633 - val_loss: 7.9930 - val_acc: 0.0196\n",
            "Epoch 55/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1616 - acc: 0.9688 - val_loss: 8.1352 - val_acc: 0.0160\n",
            "Epoch 56/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1645 - acc: 0.9657 - val_loss: 8.1593 - val_acc: 0.0239\n",
            "Epoch 57/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1896 - acc: 0.9605 - val_loss: 8.1936 - val_acc: 0.0172\n",
            "Epoch 58/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1549 - acc: 0.9676 - val_loss: 8.1065 - val_acc: 0.0178\n",
            "Epoch 59/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1304 - acc: 0.9739 - val_loss: 8.1998 - val_acc: 0.0203\n",
            "Epoch 60/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1575 - acc: 0.9667 - val_loss: 8.2448 - val_acc: 0.0135\n",
            "Epoch 61/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1752 - acc: 0.9630 - val_loss: 8.2532 - val_acc: 0.0203\n",
            "Epoch 62/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1266 - acc: 0.9782 - val_loss: 8.1681 - val_acc: 0.0178\n",
            "Epoch 63/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1956 - acc: 0.9566 - val_loss: 8.3510 - val_acc: 0.0190\n",
            "Epoch 64/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1736 - acc: 0.9601 - val_loss: 8.4384 - val_acc: 0.0172\n",
            "Epoch 65/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1596 - acc: 0.9649 - val_loss: 8.5290 - val_acc: 0.0184\n",
            "Epoch 66/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1573 - acc: 0.9645 - val_loss: 8.3572 - val_acc: 0.0184\n",
            "Epoch 67/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1154 - acc: 0.9755 - val_loss: 8.4007 - val_acc: 0.0160\n",
            "Epoch 68/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1170 - acc: 0.9735 - val_loss: 8.4746 - val_acc: 0.0203\n",
            "Epoch 69/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1236 - acc: 0.9744 - val_loss: 8.4447 - val_acc: 0.0190\n",
            "Epoch 70/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1092 - acc: 0.9758 - val_loss: 8.4829 - val_acc: 0.0233\n",
            "Epoch 71/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0792 - acc: 0.9845 - val_loss: 8.3339 - val_acc: 0.0252\n",
            "Epoch 72/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0990 - acc: 0.9794 - val_loss: 8.5245 - val_acc: 0.0233\n",
            "Epoch 73/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0847 - acc: 0.9828 - val_loss: 8.5717 - val_acc: 0.0233\n",
            "Epoch 74/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1063 - acc: 0.9754 - val_loss: 8.6192 - val_acc: 0.0209\n",
            "Epoch 75/100\n",
            "204/204 [==============================] - 11s 53ms/step - loss: 0.1227 - acc: 0.9756 - val_loss: 8.6406 - val_acc: 0.0209\n",
            "Epoch 76/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1135 - acc: 0.9734 - val_loss: 8.8663 - val_acc: 0.0172\n",
            "Epoch 77/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1411 - acc: 0.9677 - val_loss: 8.6486 - val_acc: 0.0184\n",
            "Epoch 78/100\n",
            "204/204 [==============================] - 11s 55ms/step - loss: 0.0951 - acc: 0.9795 - val_loss: 8.8729 - val_acc: 0.0196\n",
            "Epoch 79/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1090 - acc: 0.9757 - val_loss: 8.8888 - val_acc: 0.0190\n",
            "Epoch 80/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1056 - acc: 0.9775 - val_loss: 9.0419 - val_acc: 0.0196\n",
            "Epoch 81/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0989 - acc: 0.9785 - val_loss: 8.8837 - val_acc: 0.0166\n",
            "Epoch 82/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0781 - acc: 0.9847 - val_loss: 8.9213 - val_acc: 0.0160\n",
            "Epoch 83/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0858 - acc: 0.9822 - val_loss: 8.9987 - val_acc: 0.0184\n",
            "Epoch 84/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0884 - acc: 0.9780 - val_loss: 9.0468 - val_acc: 0.0221\n",
            "Epoch 85/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0941 - acc: 0.9769 - val_loss: 9.0937 - val_acc: 0.0178\n",
            "Epoch 86/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0941 - acc: 0.9797 - val_loss: 9.0630 - val_acc: 0.0196\n",
            "Epoch 87/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0964 - acc: 0.9760 - val_loss: 9.2062 - val_acc: 0.0147\n",
            "Epoch 88/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1124 - acc: 0.9724 - val_loss: 9.2167 - val_acc: 0.0196\n",
            "Epoch 89/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0904 - acc: 0.9781 - val_loss: 9.1204 - val_acc: 0.0196\n",
            "Epoch 90/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0844 - acc: 0.9805 - val_loss: 9.0135 - val_acc: 0.0153\n",
            "Epoch 91/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0937 - acc: 0.9774 - val_loss: 9.3070 - val_acc: 0.0203\n",
            "Epoch 92/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0897 - acc: 0.9810 - val_loss: 8.9953 - val_acc: 0.0246\n",
            "Epoch 93/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0716 - acc: 0.9846 - val_loss: 8.9664 - val_acc: 0.0196\n",
            "Epoch 94/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0713 - acc: 0.9824 - val_loss: 9.1387 - val_acc: 0.0196\n",
            "Epoch 95/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0778 - acc: 0.9824 - val_loss: 9.1395 - val_acc: 0.0246\n",
            "Epoch 96/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0637 - acc: 0.9842 - val_loss: 9.2710 - val_acc: 0.0190\n",
            "Epoch 97/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0641 - acc: 0.9854 - val_loss: 9.5574 - val_acc: 0.0172\n",
            "Epoch 98/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0945 - acc: 0.9738 - val_loss: 9.0903 - val_acc: 0.0203\n",
            "Epoch 99/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.0809 - acc: 0.9808 - val_loss: 9.1873 - val_acc: 0.0203\n",
            "Epoch 100/100\n",
            "204/204 [==============================] - 11s 54ms/step - loss: 0.1055 - acc: 0.9726 - val_loss: 9.1873 - val_acc: 0.0166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976026d210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZixFaWz8qq1s"
      },
      "source": [
        "model.evaluate(X_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nj-jw3owJAT"
      },
      "source": [
        "model.save('/content/drive/MyDrive/CapstoneProject/Pickles/Mobilenetclassificationmodel1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jreJcdv76WFL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}